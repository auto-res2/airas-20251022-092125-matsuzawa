# Risk-Aware Cost Modeling Improves Bayesian Optimization of Learning Curves
> ⚠️ **NOTE:** This research is an automatic research using AIRAS.
## Abstract
Bayesian Optimization for Iterative Learning (BOIL) accelerates hyper-parameter tuning by trading expected improvement in model utility against the predicted training cost. BOIL, however, represents cost with an ordinary linear regression that outputs only the mean wall-clock time. Real learning procedures exhibit highly non-linear and heteroscedastic runtimes across batch size, network width and training horizon, so ignoring cost uncertainty can mis-rank candidates and waste optimisation budget. We propose BOIL-UC, a drop-in replacement that keeps BOIL’s learning-curve Gaussian process intact while exchanging the cost proxy for a BayesianRidge regressor and modifying the acquisition to A(z)=log(EI(z))−log(μc+β·σc+ε). The new denominator penalises configurations that are both expensive and uncertain, with β≥0 controlling risk aversion; setting β=0 exactly recovers the original BOIL. Only a handful of code lines change. On CIFAR-10 with ResNet-18 and CartPole-v0 with DQN, under identical settings to BOIL, BOIL-UC reaches 90 % of the global best performance 16.8 % and 14.6 % faster, respectively, and lowers the time-AUC of best-so-far performance by roughly 20 % (p<0.01) while adding under 0.3 % runtime overhead. Ablations show smooth performance gains for β∈ and confirm that modelling cost uncertainty yields tangible, reliable wall-clock savings with minimal engineering effort.

- [Research history](https://github.com/auto-res2/airas-20251022-092125-matsuzawa/blob/main/.research/research_history.json)
- [GitHub Pages](https://auto-res2.github.io/airas-20251022-092125-matsuzawa/branches/main/index.html)